# -*- coding: utf-8 -*-
"""Anusha_Kasa_RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LlD7On0SL6WIji5kInCWZJcP3NxJosMK

importing libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.ensemble import RandomForestClassifier 
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import sklearn.metrics as metrics

"""Read dataset"""

df=pd.read_csv('/content/data-breastCancer.csv')

"""Performing EDA on Dataset"""

df.head()

df.shape

"""Checking for null values"""

df.isnull().sum()

"""As Unnamed column has many null values and there is no importance for id column we remove those columns as a part of cleaning data"""

df=df.drop(['Unnamed: 32', 'id'], axis=1)

df.head()

"""replacing diagnosis results which are malignant and benign in to 1 and 0"""

df['diagnosis']=df['diagnosis'].replace('M',1)
df['diagnosis']=df['diagnosis'].replace('B',0)

"""Plotting count plot for diagnosis to analyse the number of malignant and benign cases"""

sns.countplot(x="diagnosis", data=df)

df.describe()

"""Fitting Model"""

x = df.drop(['diagnosis'], axis=1)
y = df['diagnosis']

"""performing train test split"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""Fitting random forest classifier"""

rf = RandomForestClassifier(random_state=50)

"""Performing hyper parameter optimization using GridSearchCV"""

params = {'max_depth': [2, 3, 4],
              'bootstrap': [True, False],
              'max_features': ['auto', 'sqrt', 'log2', None],
              'criterion': ['gini', 'entropy']}

p_rf = GridSearchCV(rf, cv = 10,
                     param_grid=params, 
                     n_jobs = 3)

p_rf.fit(x_train, y_train)

rf.set_params( criterion='gini', max_depth=None,
                max_features='auto',
                max_leaf_nodes=None,
                max_samples=None,
                min_impurity_decrease=0.0,
                min_impurity_split=None,
                min_samples_leaf=1,
                min_samples_split=2,)

"""For each bootstrap sample taken from the training data, there will be samples left behind that were not included. These samples are called Out-Of-Bag samples or OOB."""

rf.set_params(warm_start=True,
              oob_score=True)
min_estimators =20
max_estimators =1000
error_rate = {}

for i in range(min_estimators, max_estimators + 1):
  rf.set_params(n_estimators=i)
  rf.fit(x_train, y_train)

  oob_error = 1-rf.oob_score_
  error_rate[i] = oob_error

oob_series = pd.Series(error_rate)

"""plotting oob error rate"""

fig, ax = plt.subplots(figsize=(12, 12))

ax.set_facecolor('#fafafa')
oob_series.plot(kind='line',
                color = 'red')
plt.axhline(0.055, 
            color='#875FDB',
           linestyle='--')
plt.axhline(0.05, 
            color='#875FDB',
           linestyle='--')
plt.xlabel('n_estimators')
plt.ylabel('OOB Error Rate')
plt.title('OOB Error Rate Across various Forest sizes')

"""As oob error score is minimum at 500 estimators, we prefer n-estimators as 500"""

rf.set_params(n_estimators=500,
                  bootstrap = True,
                  warm_start=False, 
                  oob_score=False)

rf.fit(x_train,y_train)

"""plotting feature importances using random forest """

for name, importance in zip(df.columns, rf.feature_importances_):
   print(name, "=", importance)

features=df.columns
importances = rf.feature_importances_
indices = np.argsort(importances)

plt.figure(figsize=(10,10))
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), features[indices])
plt.xlabel('Relative Importance')

"""performing k fold cross validation predicting Test Data and Plotting confusion matrix

"""

cv = KFold(n_splits=10, random_state=1, shuffle=True)
  scores = cross_val_score(rf, x, y, scoring='accuracy', cv=cv, n_jobs=-1)
  y_pred=rf.predict(x_test)
  print(classification_report(y_test,y_pred))
  cm = confusion_matrix(y_test, y_pred)
  cmd = ConfusionMatrixDisplay(cm, display_labels=['Benign','Malignant'])
  cmd.plot()

print(scores)
print(scores.mean())





"""plotting ROC curve"""

preds = y_pred
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

